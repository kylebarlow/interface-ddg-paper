%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Start the main part of the manuscript here.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Protein-protein interface interactions are important for biological systems processes.
Being able to computationally predict the strength of and perturb these interactions would not only serve as a useful experimental tool to improve our understanding of biology, but would also enhance our ability to make drugs to target new processes.

(There are over 9500 known domain-domain interactions in the PDB \cite{finn_ipfam:_2014}) In particular, a computational method capable of predicting mutations that strengthen or weaken known protein-protein interactions would provide a tool capable of precisely perturbing these interactions in such a way to generate knowledge about biological processes and function as drugs.

We set out to create a method for prediction of interface ddGs within the Rosetta macromolecular modeling suite(citation?). The preexisting state-of-the-art Rosetta ddG method,  ddg\_monomer \cite{Kellogg_role_2011}, had not yet been benchmarked on the case of mutations in interfaces of protein-protein complexes. Prior alanine scanning ddG methods were benchmarked in interfaces, but only for mutations for alanine \cite{kortemme_simple_2002,conchuir_web_2015}. These alanine scanning methods sampled only side chain degrees of freedom, which is a fair approximation to make for mutations to alanine (which are not expected to perturb the backbone very much), but not for more general mutations. Continual benchmarking is important because Benchmarks showed that ``Alanine scanning performance has not shown improvement when used with modern Rosetta score functions and aggressive side chain/backbone minimization methods'' \cite{conchuir_web_2015}.

Additionally, we set out to use ensembles. Ensembles had worked well before for prediction of change in stability ddGs \cite{benedix_predicting_2009} and to improve binding dG calculations between kinases and their inhibitors \cite{araki_effect_2016}.

As ``protein molecule in solution is quite mobile, at a range of sizes and timescales,'' (quote from Davis Backrub/Richardson paper) we are generating ensembles using Backrub. The backrub motion is based on local, coupled, side chain and backbone motions observed in high-resolution crystal structures \cite{davis_backrub_2006}. Backrub appears to recapitulate properties of proteins that have been experimentally determined. Eg NMR\cite{friedland_correspondence_2009}, sequence profiles at protein-protein interfaces \cite{humphris_prediction_2008}, sequence profiles of protein-peptide binding specificity \cite{smith_structure-based_2010,smith_predicting_2011}, and redesign of ligand-binding specificity\cite{ollikainen_coupling_2015}.

``the Backrub ensemble is the only ensemble which has a diversity that is greater than its average deviation from crystal structure, a consequence of the ability of Backrub motions to mimic high resolution dynamics from solution NMR while maintaining structural similarity to the input crystal structure''.\cite{davey_improving_2014}

\subsection{unfinished}
If all of this is true, this should help us look at the energetics of mutations in protein-protein interfaces

Why interfaces? Standard (structural) methods of ddg prdeiction( like ddg\_monomer), don't work great on interfaces, so is a good challenge to predict.

Datasets are also better and more curated than before, so a good time to reevaluate

Predicting energetic changes in functional sites such as binding interfaces is particularly important for protein design

This sets us apart from MD methods because you can’t use MD for design. Rosetta is a standard method for design.

Backrub samples local conformational space.
It has been previously shown to be successful at sequence tolerance, coupled moves, etc. (Roberto Chica).

Backrub ensemble are good \cite{schenkelberg_protein_2016}

Conformational sampling is large, and sampling it effectively is important if ensembles are to be used. Previous methods such as alanine scanning were able to succeed with a simple heuristic of assuming no backbone change, as the backbone is not likely to change for mutations to alanine.

ddG methods to cite in intro:\cite{vangone_contacts-based_2015}

\section{Methods}

A good benchmarking set is important to test a new method. Skempi \cite{moal_skempi:_2012} is the largest known database, but is not curated to be maximally effective for method development and benchmarking. Because experimental methods can have a strong effect on the performance of predictors of changes in binding free energy\cite{geng_exploring_2016}, some filtering of the entire universe of known mutations is necessary. To prevent overfitting, we have chosen to use the dataset used by ZEMU \cite{dourado_multiscale_2014}. Among other criteria, the dataset was curated to include a wide range of both stabilizing and destabilizing mutants, and to only include data published in peer-review journals.

After a review of the literature the known experimental ddG values originated from, we removed one data point from the 1254 point ZEMu set that we could not match to the original reported affinity value. We also removed 5 mutations that were duplicates and 8 mutations that were reverse mutations of other data points, leaving us with a test set of 1240 mutations.

We defined which complexes contained at least one antibody binding partner by comparison with SAbDab \cite{dunbar_sabdab:_2014}.

We implemented our flex-ddG protocol within the RosettaScripts scripting interface to the Rosetta macromolecular modeling software suite \cite{fleishman_rosettascripts_2011}, which makes the protocol easily adaptable to future improvements and energy function development. We utilized the Talaris \cite{leaver-fay_chapter_2013,song_structure-guided_2011,shapovalov_smoothed_2011} and Ref\cite{alford_rosetta_2017} energy functions in Rosetta. Version numbers of tested software are available in (Supplementary Table XXX).

Method steps are outlined in Figure 1. Step 1: The protocol begins with an initial minimization to calibrate the input model to the Rosetta energy function. This (and later) minimizations are performed with constraints that harmonically restrain pairwise atom distance to their values in the input crystal structure. Step 2: The backrub method is run, at a temperature of 1.2, and for up to 60,000 trials. 50 output structures are generated, which will be used as the base of conformational diversity for the rest of the week. Step 3A: For each of the 50 structure models in the ensemble (output by backrub), the Rosetta ``packer'' is run to search side chain space through the Dunbrack rotamer library built into Rosetta\cite{shapovalov_smoothed_2011}, optimizing side chains for the wild type sequence. Step 3B: Independently and in parallel to step 3A, the packer is run on the 50 backrub models, optimizing side chains for the mutant sequence. Step 4A: Minimization of each of the 50 wild-type structures, again adding pairwise atom-atom constraints to the input structure. Step 4B: Minimization of each of the 50 mutant structures. Step 5A: Each of the 50 minimized wild-type structures are scored in complex, and the individual complex components are scored individually. Step 5B: Each of the 50 minimized mutant structures are scored in complex, and the individual complex components are scored individually. Step 6: The interface ddG score is produced via the following formula:

\begin{equation}\label{split-ddg-equation}
  \begin{split}
    {\Delta\Delta}G_{bind} & ={\Delta}G^{MUT}_{bind} - {\Delta}G^{WT}_{bind}\\
    & =({\Delta}G^{MUT}_{complex} - {\Delta}G^{MUT}_{partner A} - {\Delta}G^{MUT}_{partner B})\\
    & \quad - ({\Delta}G^{WT}_{complex} - {\Delta}G^{WT}_{partner A} - {\Delta}G^{WT}_{partner B})\\
  \end{split}
\end{equation}

We evaluate performance of the protocol by comparing predicted ddG scores to known experimental values, using Pearson’s correlation R, MAE, and Fraction Correct (FC). Fraction Correct is defined as the number of mutations categorized as stabilizing, neutral, or destabilizing correctly, divided by the total number of mutations in the benchmark set. Stabilizing mutations are defined as those with a ddG <= -1.0 kcal/mol, neutral as those with -1.0 kcal/mol < ddG < 1.0 kcal/mol, and destabilizing as those with ddG >= 1.0 kcal/mol.

MAE (Mean Absolute Error) is defined as:
\begin{equation}\label{MAE-equation}
  MAE = \dfrac{1}{n}\sum\limits_{i=1}^n|f_i-y_i| = \dfrac{1}{n}\sum\limits_{i=1}^n|e_i|
\end{equation}

\section{Results and discussion}

Main performance of the protocol is summarized in \ref{tab:table-2}. Performance is shown for 4 prediction methods: (a) our flex ddG, backrub ensemble method, (b) the prior state-of-the-art Rosetta methodology, ddg\_monomer \cite{Kellogg_role_ 2011}, (c) a control version of our flex ddG protocol, with the backrub ensemble generation step omitted, leaving only the minimization and packing steps, and (d) the ZEMu (zone equilibration of mutants) method\cite{dourado_multiscale_2014}.

% \subimport*{figs-and-tables/}{figure-2}
\subimport*{figs-and-tables/}{figure-scatter}

Our flex ddG method outperforms the comparison methods on the complete dataset in each of the correlation, MAE, and fraction correct methods. On the small-to-large subset of mutations where we expect to see the largest performance gains from using a backbone ensemble method, we see a substantial improvement in performance as compared to the alternative methods. Performance of the flex ddG on the subset of single mutations to alanine, for which we do not expect to require intensive backbone sampling, as mutations to alanine can accommodate much of ramachandran space{ref?}, also is competitive or outperforms the alternative methods. Finally, our method shows improved performance compared to the control method and ddg\_monomer on the subset of multiple mutations, but does not match the performance of the ZEMu method. The underlying scatterplots for the flex ddG and control methods on the complete dataset and small-to-large subsets are shown in \cref{fig:figure-scatter}. Scatterplots for the underlying data behind the rest of the rows in \ref{tab:table-2} is shown in the Supplementary Information.


\cite{fig:fig4-id} shows the effect of increasing ensemble size on performance, as measured by Pearson’s R and MAE. For the complete data set and all subsets shown, correlation performance increases until the scores of about 20 structures are averaged to produce the final predicted interface ddG, after which point the returns from additional sampling diminish. MAE performance also ceases to significantly improve performance after about 20 structures. Performance improvement is most strong for the case of small-to-large mutations.

\cite{fig:fig4-WildTypeComplex} also shows the effect on performance of averaging more structures, but the structures used are first sorted by the score of the score of the corresponding repacked and minimized wild type structure. In this case, continual improvement of both correlation and MAE are seen for all subgroups as more structures are averaged, but the largest gains in performance are still obtained with the first 20-30 structures used. As it is not possible to obtain this performance by picking the 20-30 best scoring complexes without have generated an ensemble of 50 to select for, and as the performance when choosing structures sorted in this fashion is not significantly improved over \cite{fig:fig4-id} (where there is no sorting), simply generating 20-30 structures should constitute sufficient sampling for most use cases.

\section{Conclusions}

\subsection{unfinished}

\begin{itemize}
\item Monomeric Rosetta ddG does not work for interfaces
\item As stated in intro, ensembles have advantages, etc.
\item Dataset: zemu (why better than skempi). Table 1
\item General prediction protocol in figure 1
\item Metric description: pearson’s R, fraction correct, MAE
\item Description of main results, subsets, and comparison to zemu method
\item Scatter plots and table
\item Discuss fig 3 - step v correlation. Also discuss temperature, ref supplemental table/fig
\item Number of structures in ensemble average, discuss filtering structures by score (ref supp. fig). Fig 4 - one panel showing number of structures effect on correlation (at best backrub step)
\item Structure comparison - RMSD deviation are subtle. Torsions could be more informative?
\item We applied machine learning to our cases to try and study which individual score terms were informative
\end{itemize}

\subsection{more unfinished}
Local conformational sampling

Perhaps because
As the protein folding funnel is narrower near the free energy minimum {Dill, From Levinthal to pathways to funnels (include this?)}, it should be more possible to find a discrete number of states to represent in an ensemble and use in ddG modeling,
We can capture the thin part of the funnel:
“backrub sampling may capture a sizable fraction of localized conformational changes that occur in proteins” \cite{humphris_prediction_2008}

Questions:
Shouldn’t it be easier to predict interface ddGs, as we don’t need to consider the stability effects of mutants in the unfolded state
